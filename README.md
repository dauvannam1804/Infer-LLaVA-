# Infer-LLaVA
This notebook demonstrates inference with LLaVA 1.5 (Large Language and Vision Assistant) on Kaggle.
It covers:

Setting up the environment with required dependencies

Loading the LLaVA 1.5 model and tokenizer

Running inference on images and text prompts

Displaying visual outputs and model responses interactively

The goal is to provide a simple, reproducible workflow to test LLaVAâ€™s vision-language understanding for tasks like image captioning, visual question answering, and multi-modal reasoning.
